{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23a6b27a-74a3-4efc-8cc2-8e7791deb9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-06-15 13:06:34--  https://raw.githubusercontent.com/alexeygrigorev/minsearch/refs/heads/main/minsearch.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4073 (4.0K) [text/plain]\n",
      "Saving to: ‘minsearch.py.2’\n",
      "\n",
      "minsearch.py.2      100%[===================>]   3.98K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-06-15 13:06:34 (76.4 MB/s) - ‘minsearch.py.2’ saved [4073/4073]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/alexeygrigorev/minsearch/refs/heads/main/minsearch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fbbc137-725e-4fec-ae11-7b2189dac87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/LLM_zoomcamp/Homework_1/minsearch.py:10: UserWarning: Now minsearch is installable via pip: 'pip install minsearch'. Remove the downloaded file and re-install it with pip.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import minsearch\n",
    "import requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "940b591c-46e8-4918-99fd-aeccee24c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeb074f2-3e72-4815-8508-fd9b6ee3b8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65c35b35-1c36-4131-aa34-da0d829deb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4002375a-1e90-4365-8e52-f09dc219c595",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'How do execute a command on a Kubernetes pod?'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87267880-c4e8-44cb-8cb7-9627ef26c516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x7149fac174d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5913ddbd-ac86-45e1-847f-c0fc4caf8e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "boost={'question':4,\"type\": \"best_fields\"}\n",
    "results=index.search(\n",
    "    query=q,\n",
    "    boost_dict=boost,\n",
    "    num_results=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0518d010-588e-47c0-8282-4d1834d0de41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Deploy and Access the Kubernetes Dashboard\\nLuke',\n",
       "  'section': '10. Kubernetes and TensorFlow Serving',\n",
       "  'question': 'Kubernetes-dashboard',\n",
       "  'course': 'machine-learning-zoomcamp'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa41a0ba-20ce-4844-ae74-6eb10616862e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93e616c3-9b59-4d97-a1b7-c9935c8a6cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "189d444d-5fa4-4352-ae5c-fa06db887c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57e75145-25c6-4b91-89b1-8e2c2b08daba",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'the course has already started, can I still enroll?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d9e8839-3477-41a6-acea-734ff1766f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b493fce6-4c5b-48c3-95ed-b3cc0b570a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bb38c82-2476-4ada-acd1-28fd4257b862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='deepseek/deepseek-prover-v2:free',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ceb82ce0-78db-4178-bfc7-1daf81b71f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'how do I run kafka?'\n",
    "\n",
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "647f8864-5a19-4710-a0af-a507ab0bb836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"### Running Kafka in Java\\n\\nTo run a Kafka producer, consumer, or KStreams application from the terminal in Java, you can use the following command:\\n\\n```bash\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\\n```\\n\\nReplace `<jar_name>` with the actual name of your JAR file. This command sets the classpath to include both the JAR file and the `out` directory, and specifies the main class to run (`JsonProducer.java` in this example).\\n\\n### Running Kafka in Python\\n\\n**Setting Up the Environment:**\\n\\nBefore running Kafka in Python, ensure that you have set up a virtual environment and installed the necessary dependencies. Here are the steps:\\n\\n1. **Create a Virtual Environment:**\\n   ```bash\\n   python -m venv env\\n   ```\\n\\n2. **Activate the Virtual Environment:**\\n   - On MacOS and Linux:\\n     ```bash\\n     source env/bin/activate\\n     ```\\n   - On Windows:\\n     ```cmd\\n     env\\\\Scripts\\\\activate\\n     ```\\n\\n3. **Install Dependencies:**\\n   ```bash\\n   pip install -r requirements.txt\\n   ```\\n\\n4. **Deactivate the Virtual Environment:**\\n   ```bash\\n   deactivate\\n   ```\\n\\n**Note:** The virtual environment should be created and activated only to run the Python files. Ensure that all Docker containers are up and running before executing the scripts.\\n\\n### Permission Issues with build.sh (Spark Setup)\\n\\nIf you encounter a permission denied error when running `build.sh` in the `/docker/spark` directory, grant execute permissions to the script with:\\n```bash\\nchmod +x build.sh\\n```\\n\\n### Missing Kafka Python Module Error\\n\\nIf you see the error `ModuleNotFoundError: No module named 'kafka.vendor.six.moves'`, it is recommended to use `kafka-python-ng` instead of `kafka-python`. Install it with:\\n```bash\\npip install kafka-python-ng\\n```\\n\\n### Dependencies for dlt with DuckDB\\n\\nTo run code that uses `dlt` with DuckDB, ensure that both `dlt[duckdb]` and `duckdb` are installed:\\n```bash\\npip install dlt[duckdb]\\npip install duckdb\\n```\\n\\n### Steps to Run Kafka in General\\n\\nHere are the high-level steps to run Kafka (assuming you have Docker and the environment set up properly):\\n\\n1. **Start the Containers:**\\n   Navigate to the `docker` directory and run:\\n   ```bash\\n   docker compose up -d\\n   ```\\n\\n2. **Create Topics:**\\n   - Use `kafka-topics.sh` to create topics if they don't exist already.\\n\\n3. **Run Producers and Consumers:**\\n   - For Java, compile and run your Kafka producer/consumer/KStreams application using the command mentioned above.\\n   - For Python, ensure your virtual environment is activated and run the script.\\n\\n4. **Check Outputs:**\\n   - Use appropriate commands or tools (e.g., `kafka-console-consumer.sh` or `kafkacat`) to monitor topics and verify data flow.\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35379418-e327-4958-adc6-b94e2b9bc3fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94ec429-03bc-45f3-89e0-627b6db86bce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
